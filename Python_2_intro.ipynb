{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3alspaVe9FYHEQT+XiI8k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gil612/PyTorch/blob/main/Python_2_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch 2 Quick Intro\n",
        "\n",
        "* Reference notebook -"
      ],
      "metadata": {
        "id": "S7HMt2hvU0_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqZmnQyTWGHj",
        "outputId": "99bc40c4-5a40-41ae-cc91-8b4a0711c924"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quick code examples"
      ],
      "metadata": {
        "id": "X3DWnL33ZorX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before Pytorch 2.0"
      ],
      "metadata": {
        "id": "kEmhfRbIZtGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "model = torchvision.models.resnet50()"
      ],
      "metadata": {
        "id": "WC9qc-S4WGgu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After PyTorch 2.0"
      ],
      "metadata": {
        "id": "4fL_nuJlZ7PW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model = torchvision.models.resnet50()\n",
        "compiles_model=torch.compile(model)\n",
        "\n",
        "\n",
        "### Training code\n",
        "\n",
        "\n",
        "### Testing code"
      ],
      "metadata": {
        "id": "tZh1C5WSWGem"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Getting Setup"
      ],
      "metadata": {
        "id": "4619m_vUbfF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check PyTorch version\n",
        "pt_version = torch.__version__\n",
        "print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
        "\n",
        "# Install PyTorch 2.0 if necessary\n",
        "if pt_version.split(\".\")[0] == \"1\": # Check if PyTorch version begins with 1\n",
        "    !pip3 install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "    print(\"[INFO] PyTorch 2.x installed, if you're on Google Colab, you may need to restart your runtime.\\\n",
        "          Though as of April 2023, Google Colab comes with PyTorch 2.0 pre-installed.\")\n",
        "    import torch\n",
        "    pt_version = torch.__version__\n",
        "    print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
        "else:\n",
        "    print(\"[INFO] PyTorch 2.x installed, you'll be able to use the new features.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCFYIWOFWGcW",
        "outputId": "04034626-9a2b-4ba7-d222-83ccbc411410"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Current PyTorch version: 2.5.1+cu121 (should be 2.x+)\n",
            "[INFO] PyTorch 2.x installed, you'll be able to use the new features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get GPU info\n",
        "\n",
        "Why get GPU info?\n",
        "\n",
        "Because PyTorch 2.0 features (torch.compile()) work best on newer NVIDIA GPUs.\n",
        "\n",
        "> The higher the compute capability, the newer GPU, the more GPU capable is.\n",
        "\n",
        "If your GPU has a score of 8.0+, it can leverage *most* if not *all* of of the new PyTorch 2.0 features.\n",
        "\n",
        "GPUs under 8.0 can still leverage PyTorch 2.0, however, the improvement may not be as noticable as those with 8.0+\n",
        "\n",
        "**Note:** if you're wondering what GPU you should use for Deep Learning, check out Tim Dettmers blog post \"Which GPU for deep learning?\" - https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/"
      ],
      "metadata": {
        "id": "72hIIdlnbple"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we're using a NVIDIA GPU\n",
        "if torch.cuda.is_available():\n",
        "  gpu_info = !nvidia-smi\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  if gpu_info.find(\"failed\") >= 0:\n",
        "    print(\"Not connected to a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")\n",
        "\n",
        "  # Get GPU name\n",
        "  gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv\n",
        "  gpu_name = gpu_name[1]\n",
        "  GPU_NAME = gpu_name.replace(\" \", \"_\") # remove underscores for easier saving\n",
        "  print(f'GPU name: {GPU_NAME}')\n",
        "\n",
        "  # Get GPU capability score\n",
        "  GPU_SCORE = torch.cuda.get_device_capability()\n",
        "  print(f\"GPU capability score: {GPU_SCORE}\")\n",
        "  if GPU_SCORE >= (8, 0):\n",
        "    print(f\"GPU score higher than or equal to (8, 0), PyTorch 2.x speedup features available.\")\n",
        "  else:\n",
        "    print(f\"GPU score lower than (8, 0), PyTorch 2.x speedup features will be limited (PyTorch 2.x speedups happen most on newer GPUs).\")\n",
        "\n",
        "  # Print GPU info\n",
        "  print(f\"GPU information:\\n{gpu_info}\")\n",
        "\n",
        "else:\n",
        "  print(\"PyTorch couldn't find a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ6czuxcdui7",
        "outputId": "5b90745a-a02b-4cd1-ec91-b6f16d129850"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU name: Tesla_T4\n",
            "GPU capability score: (7, 5)\n",
            "GPU score lower than (8, 0), PyTorch 2.x speedup features will be limited (PyTorch 2.x speedups happen most on newer GPUs).\n",
            "GPU information:\n",
            "Mon Dec  2 22:23:47 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Globally set devices\n",
        "\n",
        "Previuosly, we've set the device of our tensors/models `.to(device)`\n",
        "\n",
        "* `tensor.to(device)`\n",
        "* `model.to(device)`\n",
        "\n",
        "But in PyTorch 2.0, it's possible to set the device with a context manager as well device"
      ],
      "metadata": {
        "id": "qcGuJWHJetR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Set the device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Set the device with context manager (requires PYtorch 2.x+)\n",
        "with torch.device(device):\n",
        "  # All tensors or PyTorch objects created in the context manager will be on the target device without using .to()\n",
        "  layer = torch.nn.Linear(20,30)\n",
        "  print(f\"Layer weights are in device: {layer.weight.device}\")\n",
        "  print(f\"Layer creating data on device: {layer(torch.randn(128, 20)).device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxgdzPX4ePjr",
        "outputId": "fc3624b4-ffdd-4096-aa37-49220e4bdecf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer weights are in device: cuda:0\n",
            "Layer creating data on device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Set the device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Set the device globally (requires PYtorch 2.x+)\n",
        "torch.set_default_device(device)\n",
        "\n",
        "# All tensors or PyTorch objects created from herer on out will be on the target device without using .to()\n",
        "layer = torch.nn.Linear(20,30)\n",
        "print(f\"Layer weights are in device: {layer.weight.device}\")\n",
        "print(f\"Layer creating data on device: {layer(torch.randn(128, 20)).device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAXK9JzAhEXx",
        "outputId": "7ee88b07-054d-44d4-a4c9-b960a901eec1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer weights are in device: cuda:0\n",
            "Layer creating data on device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Set the device globally (requires PYtorch 2.x+)\n",
        "torch.set_default_device(\"cpu\")\n",
        "\n",
        "# All tensors or PyTorch objects created from herer on out will be on the target device without using .to()\n",
        "layer = torch.nn.Linear(20,30)\n",
        "print(f\"Layer weights are in device: {layer.weight.device}\")\n",
        "print(f\"Layer creating data on device: {layer(torch.randn(128, 20)).device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTMpEAdZhEVB",
        "outputId": "5c0c467e-45e9-45b9-f900-ffd6bee169c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer weights are in device: cpu\n",
            "Layer creating data on device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Setting up the experiments\n",
        "\n",
        "Time to test speed!\n",
        "\n",
        "to keep things simple, we'll run 4 experiments:\n",
        "\n",
        "* Model: ResNet50 from torchvision\n",
        "* Data: CIFAR10 from torchvision\n",
        "* Eochs: 5 (single run) and 3x5 (multi run)\n",
        "* Batch size: 128 (note: you may want to change this depending on the amount of of memory your GPU has, this tutorial focuses on an A100)\n",
        "* Image size: 224 (note: you may want to adjust this given the amount of GPU memory you have)"
      ],
      "metadata": {
        "id": "KDtPCVBhiWA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)\n",
        "\n",
        "# Set the target device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cAQBnh0hESy",
        "outputId": "59f17935-b35e-4972-8400-9b7dfc68d402"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n",
            "0.20.1+cu121\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Create model and transforms\n",
        "* ResNet50 from PyTorch"
      ],
      "metadata": {
        "id": "FZ9WiBMDmEsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model weights and transforms\n",
        "model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2 # .DEFAULT also works\n",
        "transforms = model_weights.transforms()\n",
        "\n",
        "transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dlrk87lhEP9",
        "outputId": "c27146a1-981a-469d-aa47-dc8cea7cdbf5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[232]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BILINEAR\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "model = torchvision.models.resnet50(weights=model_weights)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2YMBo6khEMO",
        "outputId": "242f5629-1aca-41c5-816a-33fdd1a8cc39"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 185MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Couint the number of parameters in the model\n",
        "total_params = sum(\n",
        "    param.numel() for param in model.parameters() # count all parameters\n",
        "    # param.numel() for param in model.parameters() if param.requires_grad == True # only count parameters htat are trainable\n",
        ")\n",
        "total_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc8UDMcYhEKO",
        "outputId": "8fbd8cd4-a07b-4f4f-aad0-127c6c648a5a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25557032"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** PyTorch 2.0 * relative* speedups will be most noticeable when as much of the GPU as possible is being used. This means a larger model (more trainable parameters) may take konger to train on the whole but will bre relatively faster. E.g. a model with 1M paraemters may take ~10 minutes to train but a model with 25M parameters may take ~20 minutes to train."
      ],
      "metadata": {
        "id": "Za777xqenXBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(num_classes=10):\n",
        "  \"\"\"\n",
        "  Creates a resnet50 model with transforms and returns them both.\n",
        "  \"\"\"\n",
        "  model_weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
        "  transforms = model_weights.transforms()\n",
        "  model = torchvision.models.resnet50(weights=model_weights)\n",
        "\n",
        "  # Adjust the head layer to suit our number classes\n",
        "  model.fc = torch.nn.Linear(in_features=2048,\n",
        "                             out_features=num_classes)\n",
        "\n",
        "  return model, transforms\n",
        "\n",
        "model, transforms = create_model()\n",
        "transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Eykcr8ihEHd",
        "outputId": "ef05cbce-dd8a-4c2d-c4cb-331b61fe0976"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[232]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BILINEAR\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Speedups are most noticeable when a large portion of the GPU(s) is being used\n",
        "\n",
        "Since modern GPU's are son *fast* at performing operations, you will often notice the majority of *relative* speedups when as muchdata possibleis on th eGPU.\n",
        "\n",
        "In practice, you generally want to use as much of your GPU memory as possibel.\n",
        "\n",
        "* Increasing the batch size - we've been using batch size 32 nut for GPUs with a larger memory capacity you'll generally want to use as alrge possible, eg 128, 256,512, etc\n",
        "* Increasing data size = for exapmle instead of using images that are 32x32, use 224x224 or 336x336, also you could use an increased embedding size for your data\n",
        "* Increase the model size - for example instead of using a model with 1M parameters, use a model with 10M parameters\n",
        "* Decreasing data transfer - since bandwidth costs (transferring data) will slow down a GPU (because it want to compute on data)\n",
        "\n",
        "As a result of doing the above, your relative speedups should be better.\n",
        "\n",
        "E.g. overall training time may take longer but not linearly.\n",
        "\n",
        "How to improve PT model speed - https://sebastianraschka.com/blog/2023/pytorch-faster.html\n",
        "\n",
        "**Note:** This concept of using as much data on the GPU as possible isn't restricted specificialtlt to PyTorch 2.0, it applies to all versions on PyTorch and bascally all models that train on GPUs."
      ],
      "metadata": {
        "id": "MnpdvzShsC8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Checking the memory limits of our GPU"
      ],
      "metadata": {
        "id": "-RmkAwxLuvBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check availbale GPU memory and total GPU memory\n",
        "total_free_gpu_memory, total_gpu_memory = torch.cuda.mem_get_info()\n",
        "print(f\"Total free GPU memory: {round(total_free_gpu_memory * 1e-9, 3)} GB\")\n",
        "print(f\"Total GPU memory: {round(total_gpu_memory * 1e-9, 3)} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev_iPDJNhEE9",
        "outputId": "9cde653e-d2b2-455f-df76-9986eede96f0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total free GPU memory: 15.453 GB\n",
            "Total GPU memory: 15.836 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* If the GPU has 16GB+ of free memory, set batch size to 128\n",
        "* Otherwise, set batch size to 32"
      ],
      "metadata": {
        "id": "U9M9_BfCwLiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set batch size depending on amount of GPU memory\n",
        "total_free_gpu_memory_gb = round(total_free_gpu_memory * 1e-9, 3)\n",
        "if total_free_gpu_memory_gb >= 16:\n",
        "  BATCH_SIZE = 128 # Note: you could experiment with higher values here if you like.\n",
        "  IMAGE_SIZE = 224\n",
        "  print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")\n",
        "else:\n",
        "  BATCH_SIZE = 32\n",
        "  IMAGE_SIZE = 128\n",
        "  print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jc3L-LXu29A",
        "outputId": "bd8cefea-ddf1-46e9-bbd9-5ac23f2aeb40"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU memory available is 15.453 GB, using batch size of 32 and image size 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.crop_size = 224\n",
        "transforms.resize_size = 224\n",
        "print(f\"Updated data transforms:\\n{transforms}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ieRrrzdu27B",
        "outputId": "6805f8ea-f30f-487f-ca04-f3a580e18507"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated data transforms:\n",
            "ImageClassification(\n",
            "    crop_size=224\n",
            "    resize_size=224\n",
            "    mean=[0.485, 0.456, 0.406]\n",
            "    std=[0.229, 0.224, 0.225]\n",
            "    interpolation=InterpolationMode.BILINEAR\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 More potential speedups with TF32\n",
        "\n",
        "TF32 = TensorFloat32\n",
        "\n",
        "TensorFloat32 = a datatype that bridges Float32 and Float16\n",
        "\n",
        "Float32 = a number is represented by 32 bytes (e.g. 010101010110011 = 7)\n",
        "\n",
        "Float16 = a number is represented by 16 bytes (e.g. 01010101 = 4)\n",
        "\n",
        "[Precision](https://en.wikipedia.org/wiki/Precision_(computer_science))\n",
        "\n",
        "What we want is:\n",
        "1. Fast model training\n",
        "2. Accurate model training\n",
        "\n",
        "TensorFloat32 = a datatype from NVIDIA which combines float32 and float16\n",
        "\n",
        "TF32 is available on Ampere GPU+"
      ],
      "metadata": {
        "id": "_nGd-zbhxXtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPU_SCORE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTE8sERL0PnU",
        "outputId": "3836e967-db68-4bff-9e14-d0150e8ca8dc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if GPU_SCORE >= (8,0):\n",
        "  print(f\"[INFO] Using GPU with score: {GPU_SCORE}, enabling TensorFlaot32\")\n",
        "  torch.backends.cuda.matmul.allow_tf32 = True\n",
        "else:\n",
        "  print(f\"[INFO] Using GPU with score: {GPU_SCORE}, TensorFloat32 not available\")\n",
        "  torch.backends.cuda.matmul.allow_tf32 = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRPx6VmEu248",
        "outputId": "38cf613d-84b2-4dfa-8bee-7c568f67611d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU with score: (7, 5), TensorFloat32 not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 preparing datasets\n",
        "\n",
        "As before, we discussed we're going to use [CIFAR10](https://pytorch.org/vision/0.19/generated/torchvision.datasets.CIFAR10.html/)."
      ],
      "metadata": {
        "id": "W_TIoPoZ1Na2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test datasets\n",
        "import torchvision\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=\".\", # where to store data\n",
        "                                             train=True, # do we want training dataset?\n",
        "                                             download=True,\n",
        "                                             transform=transforms)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root=\".\", # where to store data\n",
        "                                             train=False, # do we want training dataset?\n",
        "                                             download=True,\n",
        "                                             transform=transforms)\n",
        "\n",
        "# Get the length of the datasets\n",
        "train_len = len(train_dataset)\n",
        "test_len = len(test_dataset)\n",
        "\n",
        "print(f\"[INFO] Train datasets length: {train_len}\")\n",
        "print(f\"[INFO] Test datasets length: {test_len}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4raxR9Lu205",
        "outputId": "ade35991-0f39-47a6-8d1f-10e7c3cbce74"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[INFO] Train datasets length: 50000\n",
            "[INFO] Test datasets length: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD4ab9h_u2yp",
        "outputId": "3a536d1c-8794-4614-ed68-2b8f593ab3b8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: .\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ImageClassification(\n",
              "               crop_size=224\n",
              "               resize_size=224\n",
              "               mean=[0.485, 0.456, 0.406]\n",
              "               std=[0.229, 0.224, 0.225]\n",
              "               interpolation=InterpolationMode.BILINEAR\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.6 Create DataLoaders\n",
        "Next:\n",
        "\n",
        "* Turn datasets into dataLoaders"
      ],
      "metadata": {
        "id": "CpTRPjPx3R2l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rkJ1j_Sgu2wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "835-T1cuu2uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jLmack5thD-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\""
      ],
      "metadata": {
        "id": "w29GJK5dgIUD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}